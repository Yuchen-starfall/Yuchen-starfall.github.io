<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="keywords" content="Hexo Theme Redefine"><meta name="author" content="Yuchen"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="canonical" href="http://example.com/2025/02/24/deep-learn -- linear regression/"><meta name="robots" content="index,follow"><meta name="googlebot" content="index,follow"><meta name="revisit-after" content="1 days"><meta name="description" content="Hexo Theme Redefine, Redefine Your Hexo Journey."><meta property="og:type" content="article"><meta property="og:title" content="Deep-learn -- linear regression"><meta property="og:url" content="http://example.com/2025/02/24/Deep-learn%20--%20linear%20regression/index.html"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="Hexo Theme Redefine, Redefine Your Hexo Journey."><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/images/redefine-og.webp"><meta property="article:published_time" content="2025-02-24T08:16:00.000Z"><meta property="article:modified_time" content="2025-03-11T06:27:00.053Z"><meta property="article:author" content="John Doe"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Deep-learn"><meta property="article:tag" content="linear regression"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://example.com/images/redefine-og.webp"><link rel="icon" type="image/png" href="/images/profile.jpg" sizes="192x192"><link rel="apple-touch-icon" sizes="180x180" href="/images/profile.jpg"><meta name="theme-color" content="#A31F34"><link rel="shortcut icon" href="/images/profile.jpg"><title>Deep-learn -- linear regression | Steps Among the Stars</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/fonts/Chillax/chillax.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/css/build/tailwind.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/fonts/GeistMono/geist-mono.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/fonts/Geist/geist.css"><script id="hexo-configurations">window.config={hostname:"example.com",root:"/",language:"en"},window.theme={articles:{style:{font_size:"16px",line_height:1.5,image_border_radius:"14px",image_alignment:"center",image_caption:!1,link_icon:!0,delete_mask:!1,title_alignment:"left",headings_top_spacing:{h1:"3.2rem",h2:"2.4rem",h3:"1.9rem",h4:"1.6rem",h5:"1.4rem",h6:"1.3rem"}},word_count:{enable:!0,count:!0,min2read:!0},author_label:{enable:!1,auto:!1,list:[]},code_block:{copy:!0,style:"mac",highlight_theme:{light:"github",dark:"vs2015"},font:{enable:!1,family:null,url:null}},toc:{enable:!0,max_depth:6,number:!1,expand:!0,init_open:!0},copyright:{enable:!0,default:"CC BY-NC-ND"},lazyload:!0,pangu_js:!1,recommendation:{enable:!1,title:"推荐阅读",limit:3,mobile_limit:2,placeholder:"/images/wallhaven-wqery6-light.webp",skip_dirs:[]}},colors:{primary:"#A31F34",secondary:null,default_mode:"light"},global:{fonts:{chinese:{enable:!1,family:null,url:null},english:{enable:!1,family:null,url:null},title:{enable:!1,family:null,url:null}},content_max_width:"1000px",sidebar_width:"210px",hover:{shadow:!0,scale:!1},scroll_progress:{bar:!1,percentage:!1},website_counter:{url:"https://cn.vercount.one/js",enable:!0,site_pv:!0,site_uv:!0,post_pv:!0},single_page:!0,preloader:{enable:"ture",custom_message:"Welcome to my little corner of chaos and brilliance!"},open_graph:{enable:!0,image:"/images/redefine-og.webp",description:"Hexo Theme Redefine, Redefine Your Hexo Journey."},google_analytics:{enable:!1,id:null}},home_banner:{enable:!0,style:"fixed",image:{light:"/images/light.jpeg",dark:"/images/dark.png"},title:"Resonant Journals",subtitle:{text:["Welcome to my little corner of chaos and brilliance!"],hitokoto:{enable:!1,show_author:!1,api:"https://v1.hitokoto.cn"},typing_speed:20,backing_speed:80,starting_delay:500,backing_delay:1500,loop:!1,smart_backspace:!0},text_color:{light:"#fff",dark:"#d1d1b6"},text_style:{title_size:"2.8rem",subtitle_size:"1.5rem",line_height:1.2},custom_font:{enable:!1,family:null,url:null},social_links:{enable:"ture",style:"default",links:{github:null,instagram:null,zhihu:null,twitter:null,email:"yuchen.starfall@outlook.com"},qrs:{weixin:null}}},plugins:{feed:{enable:!1},aplayer:{enable:!1,type:"fixed",audios:[{name:null,artist:null,url:null,cover:null,lrc:null}]},mermaid:{enable:!1,version:"11.4.1"}},version:"2.8.2",navbar:{auto_hide:"ture",color:{left:"#f78736",right:"#367df7",transparency:35},width:{home:"1200px",pages:"1000px"},links:{Home:{path:"/",icon:"fa-regular fa-house"},Archives:{path:"/archives",icon:"fa-regular fa-archive"},Categories:{icon:"fa-solid fa-folder",path:"/categories/"},Tags:{icon:"fa-solid fa-tags",path:"/tags/"}},search:{enable:!1,preload:!0}},page_templates:{friends_column:2,tags_style:"blur"},home:{sidebar:{enable:!0,position:"left",first_item:"menu",announcement:"Ephemeral Trails",show_on_mobile:!0,links:{Archives:{path:"/archives",icon:"fa-regular fa-archive"},Tags:{path:"/tags",icon:"fa-regular fa-tags"},Categories:{path:"/categories",icon:"fa-regular fa-folder"}}},article_date_format:"auto",excerpt_length:200,categories:{enable:!0,limit:3},tags:{enable:!0,limit:3}},footerStart:"2024/12/5 00:00:00"},window.lang_ago={second:"%s seconds ago",minute:"%s minutes ago",hour:"%s hours ago",day:"%s days ago",week:"%s weeks ago",month:"%s months ago",year:"%s years ago"},window.data={masonry:!0}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/fontawesome/fontawesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/fontawesome/brands.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/fontawesome/solid.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/fontawesome/regular.min.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div class="progress-bar-container"><span class="pjax-progress-bar"></span></div><main class="page-container" id="swup"><div class="main-content-container flex flex-col justify-between min-h-dvh"><div class="main-content-header"><header class="navbar-container px-6 md:px-12"><div class="navbar-content transition-navbar"><div class="left"><a class="logo-title" href="/">Steps Among the Stars</a></div><div class="right"><div class="desktop"><ul class="navbar-list"><li class="navbar-item"><a href="/"><i class="fa-regular fa-house fa-fw"></i> HOME</a></li><li class="navbar-item"><a href="/archives"><i class="fa-regular fa-archive fa-fw"></i> ARCHIVES</a></li><li class="navbar-item"><a href="/categories/"><i class="fa-solid fa-folder fa-fw"></i> CATEGORIES</a></li><li class="navbar-item"><a href="/tags/"><i class="fa-solid fa-tags fa-fw"></i> TAGS</a></li></ul></div><div class="mobile"><div class="icon-item navbar-bar"><div class="navbar-bar-middle"></div></div></div></div></div><div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between"><ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start"><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/"><span>HOME </span><i class="fa-regular fa-house fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/archives"><span>ARCHIVES </span><i class="fa-regular fa-archive fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/categories/"><span>CATEGORIES </span><i class="fa-solid fa-folder fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/tags/"><span>TAGS </span><i class="fa-solid fa-tags fa-sm fa-fw"></i></a></li></ul><div class="statistics flex justify-around my-2.5"><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">48</div><div class="label text-third-text-color text-sm">Tags</div></a><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">7</div><div class="label text-third-text-color text-sm">Categories</div></a><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">53</div><div class="label text-third-text-color text-sm">Posts</div></a></div></div><div class="window-mask"></div></header></div><div class="main-content-body transition-fade-up"><div class="main-content"><div class="post-page-container flex relative justify-between box-border w-full h-full"><div class="article-content-container"><div class="article-title relative w-full"><div class="w-full flex items-center pt-6 justify-start"><h1 class="article-title-regular text-second-text-color tracking-tight text-4xl md:text-6xl font-semibold px-2 sm:px-6 md:px-8 py-3">Deep-learn -- linear regression</h1></div></div><div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8"><div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]"><img src="/images/profile.jpg"></div><div class="info flex flex-col justify-between"><div class="author flex items-center"><span class="name text-default-text-color text-lg font-semibold">Yuchen</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fa-regular fa-pen-fancy"></i>&nbsp; <span class="desktop">2025-02-24 16:16</span> <span class="mobile">2025-02-24 16:16</span> <span class="hover-info">Created</span> </span><span class="article-date article-meta-item"><i class="fa-regular fa-wrench"></i>&nbsp; <span class="desktop">2025-03-11 14:27</span> <span class="mobile">2025-03-11 14:27</span> <span class="hover-info">Updated</span> </span><span class="article-categories article-meta-item"><i class="fa-regular fa-folders"></i>&nbsp;<ul><li><a href="/categories/Machine-Learning-and-AI-Studies/">Machine Learning and AI Studies</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fa-regular fa-tags"></i>&nbsp;<ul><li><a href="/tags/Machine-Learning/">Machine Learning</a>&nbsp;</li><li>| <a href="/tags/Deep-learn/">Deep-learn</a>&nbsp;</li><li>| <a href="/tags/linear-regression/">linear regression</a>&nbsp;</li></ul></span><span class="article-pv article-meta-item"><i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8"><h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><p><code>pip install jupyter d2l torch torchvision</code></p><p>启动：</p><p><code>jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser</code></p><p>Jupyter notebook远程访问8888端口</p><p><code>ssh -L 8888:localhost:8888 user@server_ip</code></p><h3 id="linear-regression-（线性回归）"><a href="#linear-regression-（线性回归）" class="headerlink" title="linear regression （线性回归）"></a>linear regression （线性回归）</h3><p>场景：预测美国房价 – 竞价制</p><p>线性假设是指目标（房屋价格）可以表示为特征（面积和房龄）的加权和，如下：</p><p>$$price &#x3D; w_{area} \times area + w_{age} \times age +b$$，$W$代表权重（weight），$b$​代表为偏置（bias）、</p><p>偏移量（offset）或截距（intercept）。特点是通过加权和对特征进行线性变换（linear transformation），并通过偏置项来进行平移（translation）。可以进一步的抽象为$\hat{y}&#x3D;\bf{X}\bf{w}+b$，看做一个单层神经网络（与神经元处理电信号类似）。</p><p><img lazyload src="/images/loading.svg" data-src="/img/img-learning_deeplearn/1.png"></p><h4 id="损失函数-–-衡量预估质量"><a href="#损失函数-–-衡量预估质量" class="headerlink" title="损失函数 – 衡量预估质量"></a>损失函数 – 衡量预估质量</h4><p>假设$y$是真实值，$\hat{y}$是估计值，可以得到$l(y,\hat{y}) &#x3D; \frac12(y-\hat y)^2$。这里的1&#x2F;2为了后面求导方便所加,使用的是平均损失。</p><p>$$l(\bf{X},y,w,b)&#x3D;\frac{1}{2n}\sum_{i&#x3D;1}^n (y_i-&lt;x_i,w&gt;-b)^2&#x3D;\frac{1}{2n}||y-\bf{X}w-b||$$</p><p>最小化损失来学习参数$w^<em>,b^</em>&#x3D;arg \ min_{wb}l(\bf{X},y,w,b)$，得到“最优的权重与偏移”。在一维上直观的展示为</p><p><img lazyload src="/images/loading.svg" data-src="/img/img-learning_deeplearn/2.png"></p><h4 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h4><p>唯一一个具有显示解的模型，将偏置b另附加一列放入参数w矩阵，取损失函数的w偏导数为0 可以得到$w^*&#x3D;(\bf{X}^T\bf{X})^{-1}\bf{X}^Ty$</p><p>使用梯度下降（gradient descent）是常用的求解优化算法。它通过不断地在损失函数递减的方向上更新参数来降低误差，因每次遍历所有数据集中的损失函数关于模型参数的导数， 因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本， 这种变体叫做小批量随机梯度下降（minibatch stochastic gradient descent）。</p><p>$$w_{t+1} &#x3D; w_t - \eta\frac{\frac{1}{b} \sum_b \partial l}{\partial w_{t-1}}$$</p><p>其中的$\eta$是学习率，一个超参数。b是小批量随机梯度下降中的随机采样的样本大小，同样也是超参数。</p><p><img lazyload src="/images/loading.svg" data-src="/img/img-learning_deeplearn/3.png"></p><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><ul><li>构造人造数据集。构造的数据集的$w&#x3D;[2,-3.4]^T，b &#x3D;4.2$，加上人为噪声$\epsilon$。<code>features</code>中的每一行都包含一个二维数据样本， <code>labels</code>中的每一行都包含一维标签值（一个标量）</li></ul><h1 id="X-cdot-w-begin-bmatrix-x-11-x-12-cdots-x-1n-x-21-x-22-cdots-x-2n-vdots-vdots-ddots-vdots-x-m1-x-m2-cdots-x-mn-end-bmatrix-begin-bmatrix-w-1-w-2-vdots-w-n-end-bmatrix"><a href="#X-cdot-w-begin-bmatrix-x-11-x-12-cdots-x-1n-x-21-x-22-cdots-x-2n-vdots-vdots-ddots-vdots-x-m1-x-m2-cdots-x-mn-end-bmatrix-begin-bmatrix-w-1-w-2-vdots-w-n-end-bmatrix" class="headerlink" title="$$X \cdot w &#x3D;\begin{bmatrix}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1n} \x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2n} \\vdots &amp; \vdots &amp; \ddots &amp; \vdots \x_{m1} &amp; x_{m2} &amp; \cdots &amp; x_{mn}\end{bmatrix}\begin{bmatrix}w_1 \w_2 \\vdots \w_n\end{bmatrix}"></a>$$<br>X \cdot w &#x3D;<br>\begin{bmatrix}<br>x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1n} \<br>x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2n} \<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>x_{m1} &amp; x_{m2} &amp; \cdots &amp; x_{mn}<br>\end{bmatrix}<br>\begin{bmatrix}<br>w_1 \<br>w_2 \<br>\vdots \<br>w_n<br>\end{bmatrix}</h1><p>\begin{bmatrix}<br>x_{11} \cdot w_1 + x_{12} \cdot w_2 + \cdots + x_{1n} \cdot w_n \<br>x_{21} \cdot w_1 + x_{22} \cdot w_2 + \cdots + x_{2n} \cdot w_n \<br>\vdots \<br>x_{m1} \cdot w_1 + x_{m2} \cdot w_2 + \cdots + x_{mn} \cdot w_n<br>\end{bmatrix}<br>$$</p><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># !pip install torch torch.utils d2l</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">synthetic_data</span>(<span class="params">w, b, num_examples</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成y=Xw+b+噪声&quot;&quot;&quot;</span></span><br><span class="line">    X = torch.normal(<span class="number">0</span>, <span class="number">1</span>, (num_examples, <span class="built_in">len</span>(w))) <span class="comment"># 均值，标准差，生成二维</span></span><br><span class="line">    y = torch.matmul(X, w) + b <span class="comment"># 两向量/矩阵乘</span></span><br><span class="line">    y += torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, y.shape) <span class="comment"># 噪声</span></span><br><span class="line">    <span class="keyword">return</span> X, y.reshape((-<span class="number">1</span>, <span class="number">1</span>))  <span class="comment"># 转换为列向量，转置？</span></span><br><span class="line"></span><br><span class="line">true_w = torch.tensor([<span class="number">2</span>, -<span class="number">3.4</span>]) <span class="comment"># 创建张量</span></span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features, labels = synthetic_data(true_w, true_b, <span class="number">1000</span>) <span class="comment"># features结构一千行，两列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">d2l.set_figsize()</span><br><span class="line">d2l.plt.scatter(features[:, (<span class="number">1</span>)].detach().numpy(), labels.detach().numpy(), <span class="number">1</span>); <span class="comment"># 第二列的所有行，.detach()转为numpy格式与Matplotlib兼容，末尾1代表点大小</span></span><br></pre></td></tr></table></figure></div><p><img lazyload src="/images/loading.svg" data-src="/img/img-learning_deeplearn/13.png"></p><div class="note-large blue"><div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center"><p>提示</p></div><div class="notel-content"><p><code>d2l,unmpy</code>等都可以使用mamba install直接安装，<code>torch</code>（PyTorch）通常需要通过特定的 Conda 频道安装，例如 <code>pytorch</code> 频道。默认情况下，<code>mamba</code> 可能没有配置这些频道。</p><p>解决： <code>mamba install pytorch torchvision torchaudio -c pytorch</code></p></div></div><ul><li>构造器，接收批量大小、特征矩阵和标签向量作为输入，生成大小为<code>batch_size</code>的小批量，及样本大小。 每个小批量包含一组特征和标签，为小批量随机梯度下降做准备</li></ul><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    num_examples = <span class="built_in">len</span>(features) <span class="comment"># 行数，1000</span></span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples)) <span class="comment"># list(1,2,....,1000)</span></span><br><span class="line">    <span class="comment"># 这些样本是随机读取的，没有特定的顺序</span></span><br><span class="line">    random.shuffle(indices) <span class="comment"># 直接修改原始列表，而不是返回一个新的打乱顺序的列表</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size): <span class="comment"># 最后一组不满足步长的值会被直接舍弃</span></span><br><span class="line">        batch_indices = torch.tensor(</span><br><span class="line">            indices[i: <span class="built_in">min</span>(i + batch_size, num_examples)]) <span class="comment"># 如果最后一组数据不足 batch_size，则只取剩余的部分</span></span><br><span class="line">        <span class="keyword">yield</span> features[batch_indices], labels[batch_indices]</span><br></pre></td></tr></table></figure></div><ul><li>初始化模型</li></ul><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定该张量需要计算梯度</span></span><br><span class="line">w = torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=(<span class="number">2</span>,<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></div><ul><li>定义模型,损失函数与优化算法</li></ul><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linreg</span>(<span class="params">X, w, b</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;线性回归模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(X, w) + b <span class="comment"># 矩阵点积</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">squared_loss</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;均方损失&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class="number">2</span> / <span class="number">2</span> <span class="comment"># 1/2简化求梯度</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sgd</span>(<span class="params">params, lr, batch_size</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;小批量随机梯度下降&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): <span class="comment"># 禁用梯度计算</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">            param -= lr * param.grad / batch_size <span class="comment"># 梯度下降</span></span><br><span class="line">            param.grad.zero_() <span class="comment">#重置避免梯度累计</span></span><br></pre></td></tr></table></figure></div><ul><li>训练并展示误差</li></ul><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">lr = <span class="number">0.03</span></span><br><span class="line">num_epochs = <span class="number">3</span> <span class="comment"># 迭代周期</span></span><br><span class="line">net = linreg</span><br><span class="line">loss = squared_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">        l = loss(net(X, w, b), y)  <span class="comment"># X和y的小批量损失</span></span><br><span class="line">        <span class="comment"># 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，</span></span><br><span class="line">        <span class="comment"># 并以此计算关于[w,b]的梯度</span></span><br><span class="line">        l.<span class="built_in">sum</span>().backward()</span><br><span class="line">        sgd([w, b], lr, batch_size)  <span class="comment"># 使用参数的梯度更新参数</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        train_l = loss(net(features, w, b), labels)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;<span class="built_in">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure></div><p>可以看到随着，随着多次下降，损失率下降。调参：学习率（lr），样本大小</p><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 0.042790</span><br><span class="line">epoch 2, loss 0.000162</span><br><span class="line">epoch 3, loss 0.000051</span><br></pre></td></tr></table></figure></div><p>我们不应该想当然地认为我们能够完美地求解参数。 在机器学习中，我们通常不太关心恢复真正的参数，而更关心如何高度准确预测参数。 幸运的是，即使是在复杂的优化问题上，随机梯度下降通常也能找到非常好的解。 其中一个原因是，在深度网络中存在许多参数组合能够实现高度精确的预测。</p><h4 id="高级实现-–-API"><a href="#高级实现-–-API" class="headerlink" title="高级实现 – API"></a>高级实现 – API</h4><p>许多公司、学者和业余爱好者开发了各种成熟的开源框架。 这些框架可以自动化基于梯度的学习算法中重复性的工作。</p><ul><li>生成数据集</li></ul><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">true_w = torch.tensor([<span class="number">2</span>, -<span class="number">3.4</span>])</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features, labels = d2l.synthetic_data(true_w, true_b, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure></div><ul><li>构造器</li></ul><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_array</span>(<span class="params">data_arrays, batch_size, is_train=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;构造一个PyTorch数据迭代器&quot;&quot;&quot;</span></span><br><span class="line">    dataset = data.TensorDataset(*data_arrays) <span class="comment"># 解包操作</span></span><br><span class="line">    <span class="keyword">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train) <span class="comment"># 打乱</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">data_iter = load_array((features, labels), batch_size)</span><br></pre></td></tr></table></figure></div><ul><li>定义模型，损失函数，小批量随机下降优化算法</li></ul><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">net[<span class="number">0</span>].weight.data.normal_(<span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">net[<span class="number">0</span>].bias.data.fill_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.03</span>)</span><br></pre></td></tr></table></figure></div><ul><li>训练</li></ul><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        l = loss(net(X) ,y)</span><br><span class="line">        trainer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        trainer.step()</span><br><span class="line">    l = loss(net(features), labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;l:f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure></div><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 0.000248</span><br><span class="line">epoch 2, loss 0.000103</span><br><span class="line">epoch 3, loss 0.000103</span><br></pre></td></tr></table></figure></div></div><div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8"><div class="article-copyright-info-container"><ul><li><strong>Title:</strong> Deep-learn -- linear regression</li><li><strong>Author:</strong> Yuchen</li><li><strong>Created at :</strong> 2025-02-24 16:16:00</li><li><strong>Updated at :</strong> 2025-03-11 14:27:00</li><li><strong>Link:</strong> https://yuchen-starfall.github.io/2025/02/24/Deep-learn -- linear regression/</li><li><strong>License: </strong>This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a>.</li></ul></div></div><ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden"><li class="tag-item mx-0.5"><a href="/tags/Machine-Learning/">#Machine Learning</a>&nbsp;</li><li class="tag-item mx-0.5"><a href="/tags/Deep-learn/">#Deep-learn</a>&nbsp;</li><li class="tag-item mx-0.5"><a href="/tags/linear-regression/">#linear regression</a>&nbsp;</li></ul><div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8"><div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2"><a class="prev" rel="prev" href="/2025/02/25/Genetic%20drift%20and%20Effective%20population%20size/"><span class="left arrow-icon flex justify-center items-center"><i class="fa-solid fa-chevron-left"></i> </span><span class="title flex justify-center items-center"><span class="post-nav-title-item">Genetic drift and Effective population size</span> <span class="post-nav-item">Prev posts</span></span></a></div><div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2"><a class="next" rel="next" href="/2025/02/11/Hardy-Weinberg/"><span class="title flex justify-center items-center"><span class="post-nav-title-item">Hardy-Weinberg Equilibrium (HWE)</span> <span class="post-nav-item">Next posts</span> </span><span class="right arrow-icon flex justify-center items-center"><i class="fa-solid fa-chevron-right"></i></span></a></div></div><div class="comment-container px-2 sm:px-6 md:px-8 pb-8"><div class="comments-container mt-10 w-full"><div id="comment-anchor" class="w-full h-2.5"></div><div class="comment-area-title w-full my-1.5 md:my-2.5 text-xl md:text-3xl font-bold">Comments</div><div id="giscus-container"></div><script data-swup-reload-script defer>async function loadGiscus(){const t={src:"https://giscus.app/client.js","data-repo":"Yuchen-starfall/Yuchen-starfall.github.io","data-repo-id":"R_kgDONY6r-Q","data-category":"Announcements# Github discussion category","data-category-id":"DIC_kwDONY6r-c4Ck8Zm","data-mapping":"pathname","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"1","data-theme":"preferred_color_scheme","data-lang":"en","data-input-position":"bottom","data-loading":"lazy",crossorigin:"anonymous",async:!0},a=document.createElement("script");for(const e in t)a.setAttribute(e,t[e]);document.getElementById("giscus-container").appendChild(a)}{let t=setTimeout(()=>{loadGiscus(),clearTimeout(t)},1e3)}</script></div></div></div><div class="toc-content-container"><div class="post-toc-wrap"><div class="post-toc"><div class="toc-title">On this page</div><div class="page-title">Deep-learn -- linear regression</div><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Install"><span class="nav-text">Install</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#linear-regression-%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%89"><span class="nav-text">linear regression （线性回归）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E2%80%93-%E8%A1%A1%E9%87%8F%E9%A2%84%E4%BC%B0%E8%B4%A8%E9%87%8F"><span class="nav-text">损失函数 – 衡量预估质量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0"><span class="nav-text">参数学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0"><span class="nav-text">实现</span></a></li></ol></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#X-cdot-w-begin-bmatrix-x-11-x-12-cdots-x-1n-x-21-x-22-cdots-x-2n-vdots-vdots-ddots-vdots-x-m1-x-m2-cdots-x-mn-end-bmatrix-begin-bmatrix-w-1-w-2-vdots-w-n-end-bmatrix"><span class="nav-text">$$X \cdot w &#x3D;\begin{bmatrix}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1n} \x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2n} \\vdots &amp; \vdots &amp; \ddots &amp; \vdots \x_{m1} &amp; x_{m2} &amp; \cdots &amp; x_{mn}\end{bmatrix}\begin{bmatrix}w_1 \w_2 \\vdots \w_n\end{bmatrix}</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%AB%98%E7%BA%A7%E5%AE%9E%E7%8E%B0-%E2%80%93-API"><span class="nav-text">高级实现 – API</span></a></li></ol></li></div></div></div></div></div></div><div class="main-content-footer"><footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color"><div class="info-container py-3 text-center"><div class="text-center">&copy; <span>2024</span> - 2025&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration:0.5s;color:#f54545"></i>&nbsp;&nbsp;<a href="/">Yuchen</a><p class="post-count space-x-0.5"><span>53 posts in total</span></p></div><script data-swup-reload-script src="https://cn.vercount.one/js"></script><div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right"><span id="busuanzi_container_site_uv" class="lg:!block"><span class="text-sm">VISITOR COUNT</span> <span id="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" class="lg:!block"><span class="text-sm">TOTAL PAGE VIEWS</span> <span id="busuanzi_value_site_pv"></span></span></div><div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left"><span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span> <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.2</a></span></div><div>Blog up for <span class="odometer" id="runtime_days"></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec</div><script data-swup-reload-script>try{function odometer_init(){document.querySelectorAll(".odometer").forEach(e=>{new Odometer({el:e,format:"( ddd).dd",duration:200})})}odometer_init()}catch(e){}</script></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="article-tools-list"><li class="right-bottom-tools page-aside-toggle"><i class="fa-regular fa-outdent"></i></li><li class="go-comment"><i class="fa-regular fa-comments"></i></li></ul></div></div><div class="right-side-tools-container"><div class="side-tools-container"><ul class="hidden-tools-list"><li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center"><i class="fa-regular fa-magnifying-glass-plus"></i></li><li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center"><i class="fa-regular fa-magnifying-glass-minus"></i></li><li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center"><i class="fa-regular fa-moon"></i></li><li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center"><i class="fa-regular fa-arrow-up"></i></li><li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center"><i class="fa-regular fa-arrow-down"></i></li></ul><ul class="visible-tools-list"><li class="right-bottom-tools toggle-tools-list flex justify-center items-center"><i class="fa-regular fa-cog fa-spin"></i></li></ul></div></div><div class="image-viewer-container"><img src=""></div></main><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/Swup.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/SwupSlideTheme.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/SwupScriptsPlugin.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/SwupProgressPlugin.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/SwupScrollPlugin.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/SwupPreloadPlugin.min.js"></script><script>const swup=new Swup({plugins:[new SwupScriptsPlugin({optin:!0}),new SwupProgressPlugin,new SwupScrollPlugin({offset:80}),new SwupSlideTheme({mainElement:".main-content-body"}),new SwupPreloadPlugin],containers:["#swup"]})</script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/tools/imageViewer.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/utils.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/main.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/layouts/navbarShrink.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/tools/scrollTopBottom.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/tools/lightDarkSwitch.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/layouts/categoryList.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/tools/codeBlock.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/layouts/lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/tools/runtime.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/odometer.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/assets/odometer-theme-minimal.css"><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/Typed.min.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/plugins/typed.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/minimasonry.min.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/plugins/masonry.js"></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/tools/tocToggle.js" data-swup-reload-script></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/layouts/toc.js" data-swup-reload-script></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/plugins/tabs.js" data-swup-reload-script></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/libs/moment-with-locales.min.js" data-swup-reload-script></script><script type="module" src="https://cdn.jsdelivr.net/npm/hexo-theme-redefine@2.8.2/source/js/build/layouts/essays.js" data-swup-reload-script></script></body></html>